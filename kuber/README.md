Курс "Машинное обучение в продакшене":  
https://data.mail.ru/blog/view/339/  
  
Студент:  
https://data.mail.ru/profile/v.zenin/  
  
### Домашее задание 4    
-----------
  
Выбрана локальная установка следующего продукта:  
```https://minikube.sigs.k8s.io/docs/start/```
  
#### Локальная сборка контейнера  
Поскольку я выбрал использование локального докер-образа, без использования общего репозитория:
1. В файле yaml указываем `imagePullPolicy: Never`  
2. В консоли из которой управляем кубером вводим команду: `& minikube -p minikube docker-env | Invoke-Expression`  
Примечание: вышеобозначенная команда работает для windows. Для linux команда может быть иной - корректную команду на вашей системе отобразит следующая команда: `minikube docker-env`  
3. Из этой же (важно) консоли переходим в расположение Dockerfile и выполняем сборку стандартной командой сборки для докера. Результат станет виден для кубера. Собранные иным способом контейнеры не видны. Обратите внимание, что в интерфейсе докера этого контейнера не будет, он хранится только внутри кубера.  
В моем случае это были команды:  
`cd online_inference\docker`  
`docker build -f Dockerfile -t made/inference ../..`   
4. Переходим в расположение yaml файла и производим сборку командой  
`cd kuber`  
`kuberctl apply -f online-inference-pod.yaml`  
  
Т.о. мы получили собранный под из локального докер-образа.  
  
![Скриншот](https://raw.githubusercontent.com/made-ml-in-prod-2021/vladimirzenin/homework4/kuber/pod1.png)  
  
#### Список манифестов в порядке выполнения задания
- online-inference-pod.yaml - простой под.  
- online-inference-pod-resources.yaml - под с выделением ресурсов.  
- online-inference-pod-probes.yaml - под с проверкой на работоспособность. При падении перезапускается.  
- online-inference-replicaset.yaml - создает "стадо" подов.  
- online-inference-deployment-blue-green.yaml - управляет выкаткой новых версий подов. При заданных настройках сначала поднимаются поды с новой версией, потом останавливаются старые.  
- online-inference-deployment-rolling-update.yaml - управляет выкаткой новых версий подов. При заданных настройках поочередно поднимаются новые и останавливаются старые поды (4 запустили, 2 остановили).  
  
#### resources  
В манифесте online-inference-pod-resources.yaml прописаны требуемые ресурсы приложения.
requests - количество ресурсов изначально выделяемое приложению (нормальная работа приложения).
limits - количество ресурсов до которого можно дополнительно выделять ресурсы во время работы (особые режимы работы приложения, критичные). При превышении RAM под будет перезапущен, а CPU превысить он не может, там жесткая отсечка.
  
#### probes  
В манифесте online-inference-pod-probes.yaml livenessProbe проверяет что приложение работает (даже если еще не готово), readinessProbe проверяет готовность приложения к работе. В случае сбоев происходит перезапуск.
  
#### replica
В манифесте online-inference-replicaset.yaml при увеличении количеств реплик, старые остаются со старой версией, плюс добавляются недостающие новые.  
При уменьшении количества реплик, лишние старые просто удаляются, новые не создаются.  
Онлайн смены реплик не происходит, обязательно нужно выполить пересборку командой:  
```kubectl apply -f online-inference-replicaset.yaml```  
  
#### deployment
В манифесте online-inference-deployment-blue-green.yaml: при заданных настройках сначала поднимаются поды с новой версией, потом останавливаются старые.  
В манифесте online-inference-deployment-rolling-update.yaml: при заданных настройках поочередно поднимаются новые и останавливаются старые поды (4 запустили, 2 остановили). 
  
#### Публикация второй версии образа сервера
К новому образу сервера добавлен тег v2:  
```docker tag hash_image wladimir90/made:v2```  
Опубликован по ссылке:  
```https://hub.docker.com/repository/docker/wladimir90/made```  
  
#### Helm  
Файлы helm-а расположены в папке ```charts```  
Деплой приведенных файлов успешно производится следующей командой:  
```helm upgrade --install prediction-service charts --namespace default```  

#### Самооценка (20-25 баллов)  
  
0. Установите kubectl  
1. Разверните kubernetes  
Вы можете развернуть его в облаке:  
https://cloud.google.com/kubernetes-engine  
https://mcs.mail.ru/containers/  
https://cloud.yandex.ru/services/managed-kubernetes  
Либо воспользоваться локальной инсталляцией  
https://kind.sigs.k8s.io/docs/user/quick-start/  
https://minikube.sigs.k8s.io/docs/start/  
Напишите, какой способ вы избрали.   
Убедитесь, с кластер поднялся (kubectl cluster-info)   
(5 баллов)  
Выполнено.  
2. Напишите простой pod manifests для вашего приложения, назовите его online-inference-pod.yaml (https://kubernetes.io/docs/concepts/workloads/pods/)  
Задеплойте приложение в кластер (kubectl apply -f online-inference-pod.yaml), убедитесь, что все поднялось (kubectl get pods)  
Приложите скриншот, где видно, что все поднялось  
(4 балла)  
Выполнено. 
2а: Пропишите requests/limits и напишите зачем это нужно в описание PR  
закоммитьте файл online-inference-pod-resources.yaml  
(2 балл)  
Выполнено.   
3. Модифицируйте свое приложение так, чтобы оно стартовало не сразу(с задержкой секунд 20-30) и падало спустя минуты работы.   
Добавьте liveness и readiness пробы , посмотрите что будет происходить.  
Напишите в описании -- чего вы этим добились.  
Закоммититьте отдельный манифест online-inference-pod-probes.yaml (и изменение кода приложения)  
(3 балла)  
Выполнено.  
Опубликуйте ваше приложение(из ДЗ 2) с тэгом v2
Выполнено.  
4. Создайте replicaset, сделайте 3 реплики вашего приложения. (https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/)  
Ответьте на вопрос, что будет, если сменить докер образа в манифесте и одновременно с этим   
а) уменьшить число реплик  
б) увеличить число реплик.  
Поды с какими версиями образа будут внутри будут в кластере?  
(3 балла)  
Закоммитьте online-inference-replicaset.yaml  
Выполнено.  
5. Опишите деплоймент для вашего приложения.  (https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)  
Играя с параметрами деплоя(maxSurge, maxUnavaliable), добейтесь ситуации, когда при деплое новой версии   
a) Есть момент времени, когда на кластере есть как все старые поды, так и все новые (опишите эту ситуацию) (закоммититьте файл online-inference-deployment-blue-green.yaml)  
б) одновременно с поднятием новых версии, гасятся старые (закоммитите файл online-inference-deployment-rolling-update.yaml)  
(3 балла)  
Выполнено.  
6. Бонусные активности:  
Установить helm и оформить helm chart, включить в состав чарта ConfigMap и Service. -- 5 баллов  
Выполнено частично.
  
5+4+2+3+3+3=20
А так же + частично выполненое доп. задание = 20-25 баллов
